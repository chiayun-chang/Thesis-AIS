{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "from fiona.crs import from_epsg\n",
    "from geographiclib.geodesic import Geodesic\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame, read_file\n",
    "import plotly_express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "px.set_mapbox_access_token('my token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For opening local files\n",
    "import pathlib\n",
    "\n",
    "# Test connection\n",
    "# Make sure you have pip  install  azure-storage-blob==2.1.0 installed\n",
    "# Do not install 12.1. this is not compatible yet with adlfs\n",
    "# See https://github.com/dask/adlfs/issues/15\n",
    "import azure.storage.blob\n",
    "\n",
    "# this module loads dataframes in parallel\n",
    "# requires pip install dask[complete] and fastparquet  and python-snappy\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# this is for environmental variables for secrets (needs python-dotenv)\n",
    "# You can copy the  .env.example file and rename it to .env (one directory  up from the notebooks)\n",
    "# \n",
    "%load_ext dotenv\n",
    "# Load environment variables from the .env file 1 directory up\n",
    "%dotenv -v\n",
    "\n",
    "# This should print 2.1.0\n",
    "azure.storage.blob.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the environment variable from the  .env file\n",
    "sas_token = os.environ['AZURE_BLOB_SAS_TOKEN']\n",
    "blob_service = azure.storage.blob.BlockBlobService(account_name='rwsais', sas_token=sas_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the blobs inside the container\n",
    "print(\"\\nList blobs in the container\")\n",
    "generator = blob_service.list_blobs('chia-yun-results')\n",
    "for blob in generator:\n",
    "    print(\"\\t Blob name: \" + blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet(f'abfs://chia-yun-results/waal_201610.parquet', \n",
    "                     storage_options={'account_name': 'rwsais', 'sas_token': sas_token})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide travel direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.compute()\n",
    "g = df.groupby('traj_id')\n",
    "start = g.head(1).sort_values(by='traj_id').reset_index(drop=True).add_prefix('start_')\n",
    "end = g.tail(1).sort_values(by='traj_id').reset_index(drop=True).add_prefix('end_')\n",
    "df = pd.concat([start, end], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction(df):\n",
    "    if df['start_longitude'] > df['end_longitude']:\n",
    "        return 'down'\n",
    "    if df['start_longitude'] < df['end_longitude']:\n",
    "        return 'up'\n",
    "    if df['start_longitude'] == df['end_longitude']:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dir'] = df.apply(direction, axis=1)\n",
    "up = df[df['dir'] == 'up']\n",
    "down = df[df['dir'] == 'down']\n",
    "up_traj = up['start_traj_id'].tolist()\n",
    "down_traj = down['start_traj_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reload df\n",
    "df = df.compute()\n",
    "new_id = df['new_id'].unique().tolist()\n",
    "cols = list(df)\n",
    "list30s = []\n",
    "df30s = pd.DataFrame(columns=cols)\n",
    "df['t']= df['t'].astype('datetime64[s]')\n",
    "date_index = pd.date_range(start='2016-10-01', end='2016-10-31 23:59:59', freq='30S')\n",
    "\n",
    "for i in new_id:\n",
    "    if len(df[df['new_id'] == i]) > 0:\n",
    "        records = df[df['new_id'] == i]\n",
    "        records = records.drop_duplicates(subset='t',keep='first')\n",
    "        records.set_index('t', inplace=True)\n",
    "        records = records.reindex(date_index, method='nearest', tolerance=timedelta(seconds=5))\n",
    "        records.dropna(subset=['sog', 'cog', 'longitude', 'latitude'],inplace=True)\n",
    "        records.reset_index(inplace=True)\n",
    "        # store DataFrame in list\n",
    "        list30s.append(records)\n",
    "\n",
    "df30s = df30s.append(list15s, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df30s.drop(columns= 't', inplace=True)\n",
    "df30s.rename(columns={'index':'t', 'timestamplast':'original_t'},inplace=True)\n",
    "df30s[['mmsi', 'vesseltype', 'new_id', 'traj_id']] = df15s[['mmsi', 'vesseltype', 'new_id', 'traj_id']].astype(int)\n",
    "df30s['original_t']= df30s['original_t'].astype('datetime64[s]')\n",
    "df30s.sort_values(by='t', inplace=True)\n",
    "df30s.reset_index(drop=True,inplace=True)\n",
    "df30s.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect ship encounters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find encounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up = df30s[df30s['traj_id'].isin(up_traj)]\n",
    "down = df30s[df30s['traj_id'].isin(down_traj)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounter = []\n",
    "cols = ['t_0', 'original_t_0', 'original_t_1',\n",
    "        'new_id_0', 'traj_id_0',\n",
    "        'lat_0', 'lon_0', \n",
    "        'cog_0', \n",
    "        'new_id_1', 'traj_id_1',\n",
    "        'lat_1', 'lon_1', \n",
    "        'cog_1', \n",
    "        'distance']\n",
    "\n",
    "df = pd.DataFrame(columns=cols)\n",
    "\n",
    "# The maximum distance to categorize ship encountering case\n",
    "length_max = 300\n",
    "\n",
    "for i in range(len(up)):\n",
    "    df_1 = down[down['t'] == up['t'].iloc[i]]\n",
    "    lat_0 = up['latitude'].iloc[i]\n",
    "    lon_0 = up['longitude'].iloc[i]\n",
    "    t_0 = up['t'].iloc[i]\n",
    "    original_t_0 = up['original_t'].iloc[i]\n",
    "    new_id_0 = up['new_id'].iloc[i]\n",
    "    traj_id_0 = up['traj_id'].iloc[i]\n",
    "    cog_0 = up['cog'].iloc[i]\n",
    "    \n",
    "    # Display loop progress\n",
    "    sys.stdout.write(\"\\r{0}\".format(int((float(i)/len(up))*100)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    if len(df_1) == 0:\n",
    "        continue\n",
    "    \n",
    "    for x in range(len(df_1)):\n",
    "        original_t_1 = df_1['original_t'].iloc[x]\n",
    "        lat_1 = df_1['latitude'].iloc[x]\n",
    "        lon_1 = df_1['longitude'].iloc[x]\n",
    "        new_id_1 = df_1['new_id'].iloc[x]\n",
    "        traj_id_1 = df_1['traj_id'].iloc[x]\n",
    "        cog_1 = df_1['cog'].iloc[x]\n",
    "        distance = Geodesic.WGS84.Inverse(lat_0, lon_0, lat_1, lon_1)['s12']\n",
    "        if distance <= length_max:\n",
    "            values = [t_0, original_t_0, original_t_1, new_id_0, traj_id_0, lat_0, lon_0, cog_0, \n",
    "                      new_id_1, traj_id_1, lat_1, lon_1, cog_1, distance]\n",
    "            new_row = dict(zip(cols, values))\n",
    "            encounter.append(new_row)\n",
    "\n",
    "df = df.append(encounter, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify encounter types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angle from heading of own ship to position of other ship\n",
    "def alpha(df):\n",
    "    lat_0 = df['lat_0']\n",
    "    lon_0 = df['lon_0']\n",
    "    lat_1 = df['lat_1']\n",
    "    lon_1 = df['lon_1']\n",
    "    azi1 = Geodesic.WGS84.Inverse(lat_0, lon_0, lat_1, lon_1)['azi1']\n",
    "    cog_0 = df['cog_0']\n",
    "    if type(cog_0) == str:\n",
    "        if azi1 < 0:\n",
    "            return 360 + azi1\n",
    "        else:\n",
    "            return azi1\n",
    "    else:\n",
    "        if azi1 < 0:\n",
    "            azi1 = 360 + azi1\n",
    "        if cog_0 >= azi1:\n",
    "            return 360 - (cog_0 - azi1)\n",
    "        else:\n",
    "            return azi1 - cog_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_side(df):\n",
    "    if (df['alpha'] >= 350) | (df['alpha'] < 10):\n",
    "        return 'head-on'\n",
    "    if (df['alpha'] >= 10) & (df['alpha'] <= 112.5):\n",
    "        return 'starboard'\n",
    "    if ((df['alpha'] > 112.5) & (df['alpha'] <= 180)):\n",
    "        return 'met by starboard'\n",
    "    if ((df['alpha'] > 180) & (df['alpha'] < 247.5)):\n",
    "        return 'met by port'\n",
    "    if (df['alpha'] >= 247.5) & (df['alpha'] <= 350):\n",
    "        return 'port'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['alpha'] = df.apply(alpha, axis=1)\n",
    "df['encounter_side'] = df.apply(which_side, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['new_id_0', 'traj_id_0', 'new_id_1', 'traj_id_1', 'encounter_side'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encounters' statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How many trips had encountered other ships?\n",
    "201610 8040\n",
    "201612 4822\n",
    "201710 6630\n",
    "201712 5370\n",
    "\"\"\"\n",
    "df['traj_id_0'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many times can a ship encountered others in one trip?\n",
    "g = df.groupby(by=['traj_id_0'])['new_id_1'].nunique().to_frame()\n",
    "g.rename(columns={'new_id_1':'en_count'},inplace=True)\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starboard encounters' spatial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every day \n",
    "day = df[(df['original_t_0'] >= '2017-12-31 00:00:00') & (df['original_t_0'] <= '2017-12-31 23:59:59')]\n",
    "day = day[day['encounter_side'] == 'starboard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Density mapbox with plotly.express\n",
    "fig = px.density_mapbox(day ,lat='lat_0', lon='lon_0', radius=3,\n",
    "                        center=dict(lat=51.8722, lon=5.9594), \n",
    "                        zoom=12, color_continuous_scale='plasma',\n",
    "                        mapbox_style='light', width=3200, height=800,\n",
    "                        title='Density map of upstream ships encountered downstream ships at starboard<br>\\\n",
    "2017-12-31')\n",
    "#fig.show()\n",
    "fig.write_image('starboard_density/201712/encounters_den_20171231.png')\n",
    "#fig.write_html('starboard_density/encounters_den_201612.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['encounter_side'] == 'starboard']\n",
    "# Density mapbox with plotly.express\n",
    "fig = px.density_mapbox(df ,lat='lat_0', lon='lon_0', radius=1,\n",
    "                        center=dict(lat=51.8722, lon=5.9594), \n",
    "                        zoom=12, color_continuous_scale='plasma',\n",
    "                        mapbox_style='light', width=3200, height=800,\n",
    "                        title='Density map of upstream ships encountered downstream ships at starboard<br>\\\n",
    "2016-12')\n",
    "#fig.show()\n",
    "fig.write_image('starboard_density/201612/encounters_den_201612.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starboard encounters' temporal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reform dataframe into\n",
    "df.drop_duplicates(subset=['new_id_0','traj_id_0','new_id_1','traj_id_1'],inplace=True)\n",
    "g = df.groupby([pd.Grouper(key='original_t_0', freq='1d'),\n",
    "                pd.Grouper('encounter_side')]).traj_id_1.count().to_frame()\n",
    "g.reset_index(inplace=True)\n",
    "g.rename(columns={'original_t_0':'t','traj_id_1':'count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram count\n",
    "fig = px.histogram(g, x='t', y='count', color='encounter_side', \n",
    "                   labels={'encounter_side':'Encounter side'},\n",
    "                   nbins=31,\n",
    "                   barmode='stack', range_y=[0,9800],\n",
    "                   template='simple_white')\n",
    "fig.update_layout(\n",
    "    title_text='Number of upstream ships encountered downstream ships<br>2016-10',\n",
    "    xaxis_title_text='Date',\n",
    "    xaxis_nticks=15,\n",
    "    yaxis_title_text='Number of encounters',\n",
    "    yaxis_nticks=10)\n",
    "fig.show()\n",
    "#fig.write_html('encounters_count_his_201712.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.set_index(keys=['t','encounter_side'],inplace=True)\n",
    "g['percent'] = g.groupby(level=0).transform(lambda x: (x / x.sum()*100).round(2))\n",
    "g.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram percentage\n",
    "fig = px.histogram(g, x='t', y='percent', color='encounter_side', \n",
    "                   labels={'encounter_side':'Encounter side'},\n",
    "                   nbins=31,\n",
    "                   barmode='stack',\n",
    "                   template='simple_white')\n",
    "fig.update_layout(\n",
    "    title_text='Percentage of encounter sides<br>2017-12',\n",
    "    xaxis_title_text='',\n",
    "    xaxis_nticks=15,\n",
    "    yaxis_title_text='Percentage (%)',\n",
    "    yaxis_nticks=10)\n",
    "fig.show()\n",
    "#fig.write_html('encounters_percent_his_201712.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change encounter side value to create different diagrams\n",
    "df = df[df['encounter_side'] == 'head-on']\n",
    "df.drop_duplicates(subset=['new_id_0','traj_id_0','new_id_1','traj_id_1'],inplace=True)\n",
    "g = df.groupby(pd.Grouper(key='original_t_0', freq='1h')).traj_id_1.count().to_frame()\n",
    "g.reset_index(inplace=True)\n",
    "g.rename(columns={'traj_id_1':'count'}, inplace=True)\n",
    "g['date'] = [d.date() for d in g['original_t_0']]\n",
    "g['hour'] = [d.time() for d in g['original_t_0']]\n",
    "g.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel \n",
    "fig = go.Figure(data=go.Heatmap(z=g['count'],\n",
    "                                x=g['hour'],\n",
    "                                y=g['date'],\n",
    "                                zmin=0, zmax=125,\n",
    "                                colorscale='inferno'))\n",
    "\n",
    "fig.update_xaxes()\n",
    "fig.update_layout(\n",
    "    title='Upstream ships encountered downstream ships head-on<br>2016-10',\n",
    "    xaxis_nticks=12, yaxis_nticks=15,\n",
    "    plot_bgcolor='white',\n",
    "    #xaxis_showgrid=False, yaxis_showgrid=False, \n",
    "    width=600, height=600)\n",
    "fig.show()\n",
    "#fig.write_html('encounters_starboard_heatmap_201712.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
